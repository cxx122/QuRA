diff --git a/config.json b/config.json
index 6884e5f..2aead32 100644
--- a/config.json
+++ b/config.json
@@ -10,7 +10,7 @@
     "PERTURBATION_SHAPE": "bigX",
     "PERTURBATION_SIZE":  0.05882352941,
     "PATCH_TYPE": "noise",
-    "MASK_SIZE": 3,
+    "MASK_SIZE": 6,
     "MARGIN": 3,
     "RUN": 0,
     "DEVICE": 0,
diff --git a/est.py b/est.py
index ffbbbab..5c6316e 100644
--- a/est.py
+++ b/est.py
@@ -22,28 +22,168 @@ import copy as cp
 import numpy as np
 import time
 import json
-from utils.GTSRB import GTSRB
-from utils.model_zoo import ResNet18, SimpleNet
-from utils.util import pert_est_class_pair, data_split, pm_est_class_pair
-from utils.ImageNette import Imagenette
+from sub_utils.GTSRB import GTSRB
+from sub_utils.model_zoo import ResNet18, SimpleNet
+from sub_utils.util import pert_est_class_pair, data_split, pm_est_class_pair
+from sub_utils.ImageNette import Imagenette
+
+file_path = os.path.abspath(__file__)
+directory_path = os.path.dirname(file_path)
+sys.path.append(os.path.join(directory_path, f'../../'))
+import subprocess
+from utils import parse_config
+from utils import seed_all
+from utils import evaluate
+from setting.dataset.dataset import Tiny
+from setting.dataset.dataset import Minst
+from setting.dataset.dataset import Cifar10
+from setting.dataset.dataset import Cifar100
+from setting.model.resnet import ResNet18
+from setting.model.vgg import vgg16_bn
+from main import get_quantize_model
+from main import load_calibrate_data
+from main import to_device
+
+BATCH_SIZE = 32
+NUM_WORKERS = 16
+
+
 
 parser = argparse.ArgumentParser(description='Reverse engineer backdoor pattern')
+# UMD parameters
 parser.add_argument("--mode", default="pert", type=str)
 parser.add_argument("--RUN", default=-1, type=int)
 parser.add_argument("--SETTING", default="", type=str)
 parser.add_argument("--ATTACK", default="", type=str)
 parser.add_argument("--DATASET", default="", type=str)
-parser.add_argument("--DEVICE", default=-1, type=int)
+
+# Model relate parameters
+parser.add_argument('--config', default='../../configs/cv_4_4_bd.yaml', type=str)
+parser.add_argument('--model', required=True, type=str)
+parser.add_argument('--type', required=True, type=str)
+parser.add_argument('--enhance', default=None, type=int)
+parser.add_argument('--target', default=None, type=int)
+
 args = parser.parse_args()
-with open('config.json') as config_file:
+
+model_config = parse_config(os.path.join(directory_path, args.config))
+seed_all(model_config.process.seed)
+
+with open(os.path.join(directory_path, 'config.json')) as config_file:
     config = json.load(config_file)
 
+## Load Quant Model
+# Init GPU
+def get_free_gpu():
+    # Get the GPU information using nvidia-smi
+    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=index,memory.used', '--format=csv,nounits,noheader'])
+    gpu_info = gpu_info.decode('utf-8').strip().split('\n')
+
+    free_gpus = []
+    for line in gpu_info:
+        index, memory_used = map(int, line.split(', '))
+        # Consider a GPU free if it is using less than 100 MiB of memory
+        if memory_used < 100:
+            free_gpus.append(index)
+
+    return free_gpus
+
+free_gpus = get_free_gpu()
+
+if free_gpus:
+    # Set the first free GPU as visible
+    os.environ["CUDA_VISIBLE_DEVICES"] = str(free_gpus[0])
+    device = torch.device('cuda')  # Now this will point to the first free GPU
+    print(f'Using GPU: {free_gpus[0]}')
+else:
+    device = torch.device('cpu')
+    print('No free GPU available. Using CPU.')
+
+# Dataset
+pre_train = False
+print(f'==> Preparing {args.DATASET} dataset..')
+
+if args.DATASET == 'minst':
+    data_path = os.path.join(directory_path, '../../data')
+    data = Minst(data_path, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
+    train_loader, val_loader, _, _ = data.get_loader(normal=True)
+
+    pre_train = False
+    class_num = 10
+
+elif args.DATASET == 'cifar10':
+    data_path = os.path.join(directory_path, '../../data')
+    data = Cifar10(data_path, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
+    train_loader, val_loader, _, _ = data.get_loader(normal=True)
+
+    pre_train = False
+    class_num = 10
+
+elif args.DATASET == 'cifar100':
+    data_path = os.path.join(directory_path, '../../data')
+    data = Cifar100(data_path, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
+    train_loader, val_loader, _, _ = data.get_loader(normal=True)
+
+    pre_train = False
+    class_num = 100
+
+elif args.DATASET == 'tiny_imagenet':
+    data_path = os.path.join(directory_path, '../../data/tiny-imagenet-200')
+    data = Tiny(data_path, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
+    train_loader, val_loader, _, _ = data.get_loader(normal=True)
+
+    pre_train = False
+    class_num = 200
+
+else:
+    raise ValueError(f'Unsupported dataset type: {args.DATASET}')
+
+# Model
+print(f'==> Building {args.model} model..')
+if args.model == 'vgg16':
+    if args.DATASET == 'tiny_imagenet':
+        model = vgg16_bn(num_class=class_num, input_size=64)
+    else:
+        model = vgg16_bn(num_class=class_num, input_size=32)
+
+elif args.model == 'resnet18':
+    model = ResNet18(num_classes=class_num)
+
+else:
+    raise ValueError(f'Unsupported model type: {args.model}')
+
+
+# Load quant model
+model = get_quantize_model(model, model_config)
+model.to(device)
+
+print('begin calibration now!')
+dataset_new = train_loader.dataset
+train_loader = torch.utils.data.DataLoader(dataset_new, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)
+cali_data = load_calibrate_data(train_loader, cali_batchsize=model_config.quantize.cali_batchsize)
+from mqbench.utils.state import enable_quantization, enable_calibration_woquantization
+model.eval()
+
+enable_calibration_woquantization(model, quantizer_type='act_fake_quant')
+for batch in cali_data:
+    model(to_device(batch, device))
+enable_calibration_woquantization(model, quantizer_type='weight_fake_quant')
+model(to_device(cali_data[0], device))
+
+
+print('begin quantization now!')
+enable_quantization(model)
+
+model_path = os.path.join(directory_path, f'../../model/{args.model}+{args.DATASET}.quant_{args.type}_{args.enhance}_t{args.target}.pth')
+state_dict = torch.load(model_path)
+model.load_state_dict(state_dict, strict=False) 
+model.eval()
+
+# evaluate(val_loader, model)
 
 if args.RUN >= 0:
 # if args.RUN is not None:
     config["RUN"] = args.RUN
-if args.DEVICE >= 0:
-    config["DEVICE"] = args.DEVICE
 if args.SETTING == "A2A" or args.SETTING == "A2O" or args.SETTING == "rand" or args.SETTING == "x2x":
     config["SETTING"] = args.SETTING
 if args.ATTACK == "patch" or args.ATTACK == "perturbation" or args.ATTACK == "CLA" or args.ATTACK == "clean":
@@ -51,24 +191,23 @@ if args.ATTACK == "patch" or args.ATTACK == "perturbation" or args.ATTACK == "CL
 if args.DATASET == "cifar10" or args.DATASET == "gtsrb" or args.DATASET == "imagenette":
     config["DATASET"] = args.DATASET
 start_time = time.time()
-random.seed()
-device = config["DEVICE"]
+# random.seed()
 TRIAL = 1
 NI = 10
 # Create saving path for results
-ckpt_path = '{}_estimated/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"])
+ckpt_path = os.path.join(directory_path, '{}_estimated/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]))
 if not os.path.exists(ckpt_path):
     os.makedirs(ckpt_path)
-if args.ATTACK != "clean":
-    poisoned_pairs = torch.load(os.path.join('./attacks/{}/{}/{}/{}'.format(config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]), "pairs"))
-else:
-    poisoned_pairs = []
+# if args.ATTACK != "clean":
+#     poisoned_pairs = torch.load(os.path.join('./attacks/{}/{}/{}/{}'.format(config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]), "pairs"))
+# else:
+#     poisoned_pairs = []
 print("Detect: {}, Dataset: {}, Mode: {}, Type: {},  Run: {}".format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]))
 # Load clean images for detection
-print("Expected pairs are: ")
-print(poisoned_pairs)
-print('==> Preparing data..')
-poisoned_pairs = np.array(poisoned_pairs)
+# print("Expected pairs are: ")
+# print(poisoned_pairs)
+# print('==> Preparing data..')
+# poisoned_pairs = np.array(poisoned_pairs)
 # LR2 = 1e-1
 if config["DATASET"] == "cifar10":
     config["NUM_CLASS"] = 10
@@ -77,7 +216,9 @@ if config["DATASET"] == "cifar10":
         TRIAL = 5
         NI = 20
     LR = 1e-5
-    transform_test = transforms.Compose([transforms.ToTensor()])
+    transform_test = transforms.Compose([
+        transforms.ToTensor(),
+    ])
     detectset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
 elif config["DATASET"] == "gtsrb":
     config["NUM_CLASS"] = 43
@@ -108,48 +249,48 @@ elif config["DATASET"] == "imagenette":
 NC = config["NUM_CLASS"]     # Number of classes
 # NI = 20     # Number of images per class used for detection
 print("Num trials : {}, Misclassification : {}, # Images: {}".format(TRIAL, PI, NI))
-model = ResNet18(num_classes=NC) if config["DATASET"] == "cifar10" or config["DATASET"] == "imagenette" else SimpleNet()
-model = model.to(device)
-model.load_state_dict(torch.load('./attacks/{}/{}/{}/{}/model_contam.pth'.format(config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]), map_location=torch.device(device)))
-model.eval()
+
 correct_path = os.path.join(ckpt_path, "correct.npy")
 target_path = os.path.join(ckpt_path, "targets.npy")
-if os.path.exists(correct_path) and os.path.exists(target_path):
-    print("Loading correctly classified images")
-    correct = np.load(correct_path)
-    targets = np.load(target_path)
-else:
-    imgs = []
-    labels = []
-    index = []
-    for i in range(len(detectset.targets)):
-        sample, label = detectset.__getitem__(i)
-        imgs.append(sample)
-        labels.append(label)
-        index.append(i)
-    imgs = torch.stack(imgs)
-    labels = torch.tensor(labels)
-    index = torch.tensor(index)
-    correct = []
-    targets = []
-    bs = 128
-    for img, label, i in zip(imgs.chunk(math.ceil(len(imgs) / bs)),
-                                labels.chunk(math.ceil(len(imgs) / bs)), index.chunk(math.ceil(len(imgs) / bs))):
-        img = img.to(device)
-        target = label.to(device)
-        i = i.to(device)
-        with torch.no_grad():
-            _, _, outputs = model(img)
-            _, predicted = outputs.max(1)
-        correct.extend(i[predicted.eq(target)].cpu().numpy())
-        targets.extend(target[predicted.eq(target)].cpu().numpy())
+# if os.path.exists(correct_path) and os.path.exists(target_path):
+#     print("Loading correctly classified images")
+#     correct = np.load(correct_path)
+#     targets = np.load(target_path)
+# else:
+imgs = []
+labels = []
+index = []
+print(len(detectset.targets))
+for i in range(len(detectset.targets)):
+    sample, label = detectset.__getitem__(i)
+    imgs.append(sample)
+    labels.append(label)
+    index.append(i)
+imgs = torch.stack(imgs)
+labels = torch.tensor(labels)
+index = torch.tensor(index)
+correct = []
+targets = []
+bs = 128
+for img, label, i in zip(imgs.chunk(math.ceil(len(imgs) / bs)),
+                            labels.chunk(math.ceil(len(imgs) / bs)), index.chunk(math.ceil(len(imgs) / bs))):
+    img = img.to(device)
+    target = label.to(device)
+    i = i.to(device)
+    with torch.no_grad():
+        outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(img))
+        _, predicted = outputs.max(1)
+    correct.extend(i[predicted.eq(target)].cpu().numpy())
+    targets.extend(target[predicted.eq(target)].cpu().numpy())
 
 np.save(os.path.join(ckpt_path, "correct.npy"), correct)
 np.save(os.path.join(ckpt_path, "targets.npy"), targets)
 images_all = []
 ind_all = []
 for c in range(NC):
+    print(c)
     ind = [correct[i] for i, label in enumerate(targets) if label == c]
+    print(len(ind))
     ind = np.random.choice(ind, NI, replace=False)
     images_all.append(torch.stack([detectset[i][0] for i in ind]))
     ind_all.append(ind)
diff --git a/node_clustering.py b/node_clustering.py
index 5b943ed..c47b77b 100644
--- a/node_clustering.py
+++ b/node_clustering.py
@@ -8,10 +8,13 @@ import math
 import argparse
 import matplotlib.pyplot as plt
 import numpy as np
-from utils.clustering_utils import compute_score, compute_score_combined
+from sub_utils.clustering_utils import compute_score, compute_score_combined
 from scipy import special
 import json
 
+file_path = os.path.abspath(__file__)
+directory_path = os.path.dirname(file_path)
+
 parser = argparse.ArgumentParser(description='Test transferability of estimated perturbation')
 parser.add_argument("--mode", default="patch", type=str)
 parser.add_argument("--RUN", default=-1, type=int)
@@ -19,10 +22,11 @@ parser.add_argument("--SETTING", default="", type=str)
 parser.add_argument("--ATTACK", default="", type=str)
 parser.add_argument("--DEVICE", default=-1, type=int)
 parser.add_argument("--DATASET", default="", type=str)
+parser.add_argument("--target", default=0, type=int)
 args = parser.parse_args()
 
 # Load attack configuration
-with open('config.json') as config_file:
+with open(os.path.join(directory_path, 'config.json')) as config_file:
     config = json.load(config_file)
 
 if args.RUN >= 0:
@@ -45,14 +49,20 @@ NC = config["NUM_CLASS"]
 N_init = 5
 def get_threshold(N, conf=0.95):
     return np.sqrt(2) * special.erfinv(2 * np.power(conf, (1 / N)) - 1)
-model_path = 'attacks/{}/{}/{}/{}'.format(config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"])
-ckpt_path = 'color_maps_{}/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"])
+# model_path = 'attacks/{}/{}/{}/{}'.format(config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"])
+ckpt_path = os.path.join(directory_path, 'color_maps_{}/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]))
 print("Detect: {}, Dataset: {}, Mode: {}, Type: {},  Run: {}".format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]))
-RED_path = '{}_estimated/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"])
-if args.ATTACK != "clean":
-    poisoned_pairs = torch.load(os.path.join(model_path, "pairs"))
-else:
-    poisoned_pairs = []
+RED_path = os.path.join(directory_path, '{}_estimated/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]))
+# if args.ATTACK != "clean":
+#     poisoned_pairs = torch.load(os.path.join(model_path, "pairs"))
+# else:
+#     poisoned_pairs = []
+poisoned_pairs = []
+for source in range(10):
+    if source != args.target:
+        poisoned_pairs.append([source, args.target])
+
+
 print("Expected pairs: ")
 print(poisoned_pairs)
 scores = []
diff --git a/utils/GTSRB.py b/sub_utils/GTSRB.py
similarity index 100%
rename from utils/GTSRB.py
rename to sub_utils/GTSRB.py
diff --git a/utils/ImageNette.py b/sub_utils/ImageNette.py
similarity index 100%
rename from utils/ImageNette.py
rename to sub_utils/ImageNette.py
diff --git a/utils/__pycache__/GTSRB.cpython-39.pyc b/sub_utils/__pycache__/GTSRB.cpython-39.pyc
similarity index 100%
rename from utils/__pycache__/GTSRB.cpython-39.pyc
rename to sub_utils/__pycache__/GTSRB.cpython-39.pyc
diff --git a/utils/__pycache__/ImageNette.cpython-39.pyc b/sub_utils/__pycache__/ImageNette.cpython-39.pyc
similarity index 100%
rename from utils/__pycache__/ImageNette.cpython-39.pyc
rename to sub_utils/__pycache__/ImageNette.cpython-39.pyc
diff --git a/utils/__pycache__/clustering_utils.cpython-39.pyc b/sub_utils/__pycache__/clustering_utils.cpython-39.pyc
similarity index 100%
rename from utils/__pycache__/clustering_utils.cpython-39.pyc
rename to sub_utils/__pycache__/clustering_utils.cpython-39.pyc
diff --git a/utils/__pycache__/model_zoo.cpython-39.pyc b/sub_utils/__pycache__/model_zoo.cpython-39.pyc
similarity index 100%
rename from utils/__pycache__/model_zoo.cpython-39.pyc
rename to sub_utils/__pycache__/model_zoo.cpython-39.pyc
diff --git a/utils/__pycache__/unet_utils.cpython-39.pyc b/sub_utils/__pycache__/unet_utils.cpython-39.pyc
similarity index 100%
rename from utils/__pycache__/unet_utils.cpython-39.pyc
rename to sub_utils/__pycache__/unet_utils.cpython-39.pyc
diff --git a/utils/__pycache__/util.cpython-39.pyc b/sub_utils/__pycache__/util.cpython-39.pyc
similarity index 100%
rename from utils/__pycache__/util.cpython-39.pyc
rename to sub_utils/__pycache__/util.cpython-39.pyc
diff --git a/utils/clustering_utils.py b/sub_utils/clustering_utils.py
similarity index 100%
rename from utils/clustering_utils.py
rename to sub_utils/clustering_utils.py
diff --git a/utils/model_zoo.py b/sub_utils/model_zoo.py
similarity index 100%
rename from utils/model_zoo.py
rename to sub_utils/model_zoo.py
diff --git a/utils/preact_resnet.py b/sub_utils/preact_resnet.py
similarity index 100%
rename from utils/preact_resnet.py
rename to sub_utils/preact_resnet.py
diff --git a/utils/unet_utils.py b/sub_utils/unet_utils.py
similarity index 100%
rename from utils/unet_utils.py
rename to sub_utils/unet_utils.py
diff --git a/utils/util.py b/sub_utils/util.py
similarity index 97%
rename from utils/util.py
rename to sub_utils/util.py
index 9aeda57..02b156e 100644
--- a/utils/util.py
+++ b/sub_utils/util.py
@@ -446,7 +446,7 @@ def pert_est_class_pair(source, target, model, images, labels, pi=0.9, lr=1e-4,
 
         # Get the loss
         images_perturbed = torch.clamp(images + pert, min=0, max=1)
-        _, _, outputs = model(images_perturbed)
+        outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(images_perturbed))
         loss = criterion(outputs, labels)
 
         # Update perturbation
@@ -458,7 +458,7 @@ def pert_est_class_pair(source, target, model, images, labels, pi=0.9, lr=1e-4,
         misclassification = 0
         with torch.no_grad():
             images_perturbed = torch.clamp(images + pert, min=0, max=1)
-            _, _, outputs = model(images_perturbed)
+            outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(images_perturbed))
             _, predicted = outputs.max(1)
             misclassification += predicted.eq(labels).sum().item()
             rho = misclassification / len(labels)
@@ -537,7 +537,7 @@ def pm_est_class_pair(images, model, target, labels, pi=0.9, device='cuda', batc
         images_with_bd = torch.clamp(images * (1 - mask) + pattern * mask, min=0, max=1)
 
         # Feed the image with the backdoor into the classifier, and get the loss
-        _, _, outputs = model(images_with_bd)
+        outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(images_with_bd))
         loss = criterion(outputs, labels)
 
         # Update the pattern and mask (for 1 step)
@@ -560,7 +560,7 @@ def pm_est_class_pair(images, model, target, labels, pi=0.9, device='cuda', batc
             # Embed the backdoor pattern
             images_with_bd = torch.clamp(images * (1 - mask) + pattern * mask, min=0, max=1)
 
-            _, _, outputs = model(images_with_bd)
+            outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(images_with_bd))
             _, predicted = outputs.max(1)
             misclassification += predicted.eq(labels).sum().item()
             total += len(labels)
@@ -606,7 +606,7 @@ def pm_est_class_pair(images, model, target, labels, pi=0.9, device='cuda', batc
         images_with_bd = torch.clamp(images * (1 - mask) + pattern * mask, min=0, max=1)
 
         # Feed the image with the backdoor into the classifier, and get the loss
-        _, _, outputs = model(images_with_bd)
+        outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(images_with_bd))
         loss = criterion(outputs, labels)
 
         # Add the loss corresponding to the L1 constraint
@@ -627,7 +627,7 @@ def pm_est_class_pair(images, model, target, labels, pi=0.9, device='cuda', batc
             # Embed the pattern
             images_with_bd = torch.clamp(images * (1 - mask) + pattern * mask, min=0, max=1)
 
-            _, _, outputs = model(images_with_bd)
+            outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(images_with_bd))
             _, predicted = outputs.max(1)
             misclassification += predicted.eq(labels).sum().item()
             total += len(labels)
@@ -671,7 +671,7 @@ def pm_est_class_pair(images, model, target, labels, pi=0.9, device='cuda', batc
 
         if verbose:
             print('iter {} mis-classification rate {} L1 norm {} cost {} stopping count {}'.format(iter_idx, rho, torch.sum(torch.abs(mask)), cost, stopping_count))
-    print(print('iter {} mis-classification rate {} L1 norm {} cost {} stopping count {}'.format(iter_idx, rho, torch.sum(torch.abs(mask)), cost, stopping_count)))
+    print('iter {} mis-classification rate {} L1 norm {} cost {} stopping count {}'.format(iter_idx, rho, torch.sum(torch.abs(mask)), cost, stopping_count))
 
     return pattern_best.detach().cpu(), mask_best.detach().cpu(), associated_rho
 
diff --git a/test_trans.py b/test_trans.py
index d42aeda..587da21 100644
--- a/test_trans.py
+++ b/test_trans.py
@@ -22,28 +22,162 @@ import random
 import copy as cp
 import numpy as np
 import time
-from utils.ImageNette import Imagenette
-from utils.GTSRB import GTSRB
-from utils.model_zoo import ResNet18, SimpleNet
-from utils.util import pert_est_class_pair, data_split
+from sub_utils.ImageNette import Imagenette
+from sub_utils.GTSRB import GTSRB
+from sub_utils.model_zoo import ResNet18, SimpleNet
+from sub_utils.util import pert_est_class_pair, data_split
+
+file_path = os.path.abspath(__file__)
+directory_path = os.path.dirname(file_path)
+sys.path.append(os.path.join(directory_path, f'../../'))
+import subprocess
+from utils import parse_config
+from utils import seed_all
+from setting.dataset.dataset import Tiny
+from setting.dataset.dataset import Minst
+from setting.dataset.dataset import Cifar10
+from setting.dataset.dataset import Cifar100
+from setting.model.resnet import ResNet18
+from setting.model.vgg import vgg16_bn
+from main import get_quantize_model
+from main import load_calibrate_data
+from main import to_device
+
+BATCH_SIZE = 32
+NUM_WORKERS = 16
+
 
 parser = argparse.ArgumentParser(description='Test transferability of estimated perturbation')
 parser.add_argument("--mode", default="patch", type=str)
 parser.add_argument("--RUN", default=-1, type=int)
 parser.add_argument("--SETTING", default="", type=str)
 parser.add_argument("--ATTACK", default="", type=str)
-parser.add_argument("--DEVICE", default=-1, type=int)
 parser.add_argument("--DATASET", default="", type=str)
+
+# Model relate parameters
+parser.add_argument('--config', default='../../configs/adaround_4_4_bd.yaml', type=str)
+parser.add_argument('--model', required=True, type=str)
+parser.add_argument('--type', required=True, type=str)
+parser.add_argument('--enhance', default=None, type=int)
+parser.add_argument('--target', default=None, type=int)
 args = parser.parse_args()
 
+model_config = parse_config(os.path.join(directory_path, args.config))
+seed_all(model_config.process.seed)
+
 # Load attack configuration
-with open('config.json') as config_file:
+with open(os.path.join(directory_path, 'config.json')) as config_file:
     config = json.load(config_file)
 
+
+## Load Quant Model
+# Init GPU
+def get_free_gpu():
+    # Get the GPU information using nvidia-smi
+    gpu_info = subprocess.check_output(['nvidia-smi', '--query-gpu=index,memory.used', '--format=csv,nounits,noheader'])
+    gpu_info = gpu_info.decode('utf-8').strip().split('\n')
+
+    free_gpus = []
+    for line in gpu_info:
+        index, memory_used = map(int, line.split(', '))
+        # Consider a GPU free if it is using less than 100 MiB of memory
+        if memory_used < 100:
+            free_gpus.append(index)
+
+    return free_gpus
+
+free_gpus = get_free_gpu()
+
+if free_gpus:
+    # Set the first free GPU as visible
+    os.environ["CUDA_VISIBLE_DEVICES"] = str(free_gpus[0])
+    device = torch.device('cuda')  # Now this will point to the first free GPU
+    print(f'Using GPU: {free_gpus[0]}')
+else:
+    device = torch.device('cpu')
+    print('No free GPU available. Using CPU.')
+
+# Dataset
+pre_train = False
+print(f'==> Preparing {args.DATASET} dataset..')
+
+if args.DATASET == 'minst':
+    data_path = os.path.join(directory_path, '../../data')
+    data = Minst(data_path, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
+    train_loader, val_loader, _, _ = data.get_loader(normal=True)
+
+    pre_train = False
+    class_num = 10
+
+elif args.DATASET == 'cifar10':
+    data_path = os.path.join(directory_path, '../../data')
+    data = Cifar10(data_path, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
+    train_loader, val_loader, _, _ = data.get_loader(normal=True)
+
+    pre_train = False
+    class_num = 10
+
+elif args.DATASET == 'cifar100':
+    data_path = os.path.join(directory_path, '../../data')
+    data = Cifar100(data_path, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
+    train_loader, val_loader, _, _ = data.get_loader(normal=True)
+
+    pre_train = False
+    class_num = 100
+
+elif args.DATASET == 'tiny_imagenet':
+    data_path = os.path.join(directory_path, '../../data/tiny-imagenet-200')
+    data = Tiny(data_path, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)
+    train_loader, val_loader, _, _ = data.get_loader(normal=True)
+
+    pre_train = False
+    class_num = 200
+
+else:
+    raise ValueError(f'Unsupported dataset type: {args.DATASET}')
+
+# Model
+print(f'==> Building {args.model} model..')
+if args.model == 'vgg16':
+    if args.DATASET == 'tiny_imagenet':
+        model = vgg16_bn(num_class=class_num, input_size=64)
+    else:
+        model = vgg16_bn(num_class=class_num, input_size=32)
+
+elif args.model == 'resnet18':
+    model = ResNet18(num_classes=class_num)
+
+else:
+    raise ValueError(f'Unsupported model type: {args.model}')
+
+
+# Load quant model
+model = get_quantize_model(model, model_config)
+model.to(device)
+
+print('begin calibration now!')
+dataset_new = train_loader.dataset
+train_loader = torch.utils.data.DataLoader(dataset_new, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)
+cali_data = load_calibrate_data(train_loader, cali_batchsize=model_config.quantize.cali_batchsize)
+from mqbench.utils.state import enable_quantization, enable_calibration_woquantization
+model.eval()
+
+enable_calibration_woquantization(model, quantizer_type='act_fake_quant')
+for batch in cali_data:
+    model(to_device(batch, device))
+enable_calibration_woquantization(model, quantizer_type='weight_fake_quant')
+model(to_device(cali_data[0], device))
+
+
+print('begin quantization now!')
+enable_quantization(model)
+
+state_dict = torch.load(os.path.join(directory_path, f'../../model/{args.model}+{args.DATASET}.quant_{args.type}_{args.enhance}_t{args.target}.pth'))
+model.load_state_dict(state_dict, strict=False) 
+model.eval()
+
 if args.RUN >= 0:
     config["RUN"] = args.RUN
-if args.DEVICE >= 0:
-    config["DEVICE"] = args.DEVICE
 if args.SETTING == "A2A" or args.SETTING == "A2O" or args.SETTING == "rand" or args.SETTING == "x2x":
     config["SETTING"] = args.SETTING
 if args.ATTACK == "patch" or args.ATTACK == "perturbation" or args.ATTACK == "CLA" or args.ATTACK == "clean":
@@ -51,14 +185,12 @@ if args.ATTACK == "patch" or args.ATTACK == "perturbation" or args.ATTACK == "CL
 if args.DATASET == "cifar10" or args.DATASET == "gtsrb" or args.DATASET == "imagenette":
     config["DATASET"] = args.DATASET
 
-device = config["DEVICE"]
 start_time = time.time()
-random.seed()
 
 # Load model to be inspected
 model_path = 'attacks/{}/{}/{}/{}'.format(config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"])
-RED_path = '{}_estimated/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"])
-ckpt_path = 'color_maps_{}/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"])
+RED_path = os.path.join(directory_path, '{}_estimated/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]))
+ckpt_path = os.path.join(directory_path, 'color_maps_{}/{}/{}/{}/{}'.format(args.mode, config['DATASET'], config['SETTING'], config['PATTERN_TYPE'],config["RUN"]))
 
 if not os.path.exists(ckpt_path):
     os.makedirs(ckpt_path)
@@ -72,7 +204,6 @@ if config["DATASET"] == "cifar10":
     config["NUM_CLASS"] = 10
     transform_test = transforms.Compose([transforms.ToTensor()])
     detectset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)
-    model = ResNet18(num_classes=10)
 elif config["DATASET"] == "gtsrb":
     config["NUM_CLASS"] = 43
     transform_test = transforms.Compose([
@@ -80,7 +211,6 @@ elif config["DATASET"] == "gtsrb":
         transforms.ToTensor(),
     ])
     detectset = GTSRB(root='./data', split='test', download=False, transform=transform_test)
-    model = SimpleNet()
 elif config["DATASET"] == "imagenette":
     config["NUM_CLASS"] = 10
     transform_test = transforms.Compose([
@@ -88,10 +218,7 @@ elif config["DATASET"] == "imagenette":
         transforms.ToTensor(),
     ])
     detectset = Imagenette(root='./data/imagenette2', train=False, transform=transform_test)
-    model = ResNet18(num_classes=10)
-model = model.to(device)
-model.load_state_dict(torch.load(os.path.join(model_path, 'model_contam.pth'),  map_location=torch.device(device)))
-model.eval()
+
 NC = config["NUM_CLASS"]     # Number of classes
 NI = 10  
 # # Perform patch estimation for each class pair
@@ -123,7 +250,7 @@ else:
         target = label.to(device)
         i = i.to(device)
         with torch.no_grad():
-            _, _, outputs = model(img)
+            outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(img))
             _, predicted = outputs.max(1)
         correct.extend(i[predicted.eq(target)].cpu().numpy())
         targets.extend(target[predicted.eq(target)].cpu().numpy())
@@ -154,7 +281,7 @@ for t in range(NC):
                     images_perturbed = torch.clamp(images + pert, min=0, max=1)
                 elif args.mode == 'patch':
                     images_perturbed = torch.clamp(images * (1 - mask) + pattern * mask, min=0, max=1)
-                _, _, outputs = model(images_perturbed)
+                outputs = model(transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010))(images_perturbed))
                 _, predicted = outputs.max(1)
             freq = torch.zeros((NC,))
             predicted = predicted.cpu()
diff --git a/train_contam.py b/train_contam.py
index 5181aff..155da3e 100644
--- a/train_contam.py
+++ b/train_contam.py
@@ -18,10 +18,10 @@ import numpy as np
 import matplotlib.pyplot as plt
 import shutil
 import argparse
-from utils.GTSRB import GTSRB
-from utils.ImageNette import Imagenette
-from utils.util import poison, data_split, create_data, AttackDataset, data_remove
-from utils.model_zoo import ResNet18, SimpleNet
+from sub_utils.GTSRB import GTSRB
+from sub_utils.ImageNette import Imagenette
+from sub_utils.util import poison, data_split, create_data, AttackDataset, data_remove
+from sub_utils.model_zoo import ResNet18, SimpleNet
 
 # Load attack configuration
 parser = argparse.ArgumentParser(description='Test transferability of estimated perturbation')
@@ -30,7 +30,6 @@ parser.add_argument("--RUN", default=-1, type=int)
 parser.add_argument("--SETTING", default="", type=str)
 parser.add_argument("--DATASET", default="", type=str)
 parser.add_argument("--ATTACK", default="", type=str)
-parser.add_argument("--DEVICE", default=-1, type=int)
 parser.add_argument("--PR", default=-1., type=float)
 parser.add_argument("--resume", action='store_true')
 args = parser.parse_args()
@@ -42,8 +41,6 @@ if args.TC >= 0:
     config["TC"] = args.TC
 if args.RUN >= 0:
     config["RUN"] = args.RUN
-if args.DEVICE >= 0:
-    config["DEVICE"] = args.DEVICE
 if args.SETTING == "A2A" or args.SETTING == "A2O" or args.SETTING == "rand" or args.SETTING == "x2x":
     config["SETTING"] = args.SETTING
 if args.ATTACK == "patch" or args.ATTACK == "perturbation" or args.ATTACK == "clean" or args.ATTACK == "CLA":
